{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchPredict,DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxex (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "                                \n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "                                \n",
    "        segmentation = np.array([x['segmentation'] for x in anns], dtype=object)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "\n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "data_dir = './input/data'\n",
    "annotation = './input/data/test.json'\n",
    "test_dataset = CustomDataset(annotation, data_dir, get_valid_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    config.norm_kwargs=dict(eps=.001, momentum=.01)\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=False)    \n",
    "    \n",
    "    net.reset_head(num_classes=11)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)    \n",
    "    \n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)    \n",
    "#     net.load_state_dict(checkpoint,strict=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    gc.collect()\n",
    "    net = DetBenchPredict(net)\n",
    "    net.eval();\n",
    "    return net.cuda()\n",
    "\n",
    "net = load_net('./tf_efficientdet_d5/last-checkpoint.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/837 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for images, targets, image_ids in tqdm(data_loader):\n",
    "    break\n",
    "# gpu 계산을 위해 image.to(device)\n",
    "images = torch.stack(images).cuda().float()        \n",
    "det = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(val_data_loader, model, device):\n",
    "    outputs = []\n",
    "    for images, targets, image_ids in tqdm(val_data_loader):\n",
    "        # gpu 계산을 위해 image.to(device)\n",
    "        images = torch.stack(images).cuda().float()\n",
    "        output = model(images)\n",
    "        for out in output:\n",
    "            outputs.append({'boxes': out['boxes'].tolist(), 'scores': out['scores'].tolist(), 'labels': out['labels'].tolist()})\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(val_data_loader, model, device,score_threshold=0.0):\n",
    "    predictions = []\n",
    "    for images, targets, image_ids in tqdm(val_data_loader):\n",
    "        # gpu 계산을 위해 image.to(device)\n",
    "        images = torch.stack(images).cuda().float()        \n",
    "        with torch.no_grad():\n",
    "            det = net(images) #, torch.tensor([1]*images.shape[0]).float().cuda()        \n",
    "            for i in range(images.shape[0]):\n",
    "                boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "                scores = det[i].detach().cpu().numpy()[:,4]\n",
    "                labels = det[i].detach().cpu().numpy()[:,5]\n",
    "                indexes = np.where(scores > score_threshold)[0]\n",
    "                boxes = boxes[indexes]\n",
    "                boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "                predictions.append({\n",
    "                    'boxes': boxes[indexes],\n",
    "                    'scores': scores[indexes],\n",
    "                    'labels': labels[indexes]\n",
    "                })\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 372/837 [00:47<00:57,  8.07it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in add\n",
      "  \n",
      "100%|██████████| 837/837 [01:46<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "outputs = valid_fn(data_loader, net, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString              image_id\n",
      "0  2.0 0.21496797 1031.3042 238.27869 2114.628 52...  batch_01_vt/0021.jpg\n",
      "1  2.0 0.21141881 967.3356 243.84966 1985.8867 53...  batch_01_vt/0028.jpg\n",
      "2  2.0 0.21466209 963.8663 244.38239 1980.0585 53...  batch_01_vt/0031.jpg\n",
      "3  8.0 0.22500965 1030.694 239.30667 2114.3645 53...  batch_01_vt/0032.jpg\n",
      "4  2.0 0.199258 1032.443 238.38881 2115.4553 528....  batch_01_vt/0070.jpg\n"
     ]
    }
   ],
   "source": [
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(annotation)\n",
    "score_threshold = 0.05\n",
    "for i, output in enumerate(outputs):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "        if score > score_threshold:\n",
    "            prediction_string += str(label) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "                box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(f'submission.csv', index=None)\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
