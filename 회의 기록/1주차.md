# 04/26

1. Ground rule 정하기 

2. 회의 기록

   * Base line을 학습 시키면 생각보다 오래 걸린다.
   * Base line이 잘 작성되어있다.
   * 서버 할당을 받지 못하여, 모델 코드에 대한 이해 부족
   * unknown과 background 차이
   * 파악이 안된 unknown에 대해 어떻게 할 것인가?
     
     * https://arxiv.org/abs/1804.04340
   * 몇몇 이미지가 분류가 어려울 것 같다.
   * Git 운영 방식에 대한 이야기
     * 각자 구현한 내용을 바탕으로 1개의 코드를 만들어보자
     * Train, model, loss, Dataset 으로 구성
     



# 04/27

1. 프로젝트 팀 게시판에 글 작성
2. 서버에서 자동으로 제출하는 방법을 submit.py로 제작
   * Team git에서 확인 가능
3. 이번주에는 점수에 집중하기보단, 전체적인 모델에 대해 파악 할 예정 - 김현우님
4. resize를 꼭 해야한다. 예측하는 결과 용량이 너무 크다 
   * resize를 사용하여도, 결과 예측에 큰 영향이 있지 않다.
5. inference를 줄이는 방법을 생각해 봐야한다. 
6. torchvision model을 사용하여 submission 생성에 어려움이 있다 - 김종호님
7. 시드 고정하기 - 21
8. git 사용시, 각자 branch 생성 후 사용
9. 중요한 Code의 경우 master에 PR



# 04/28

1. Deep v3 - 0.36 pretrained x -  pretrained를 할 경우 0.5 이상 
2. Deep v3 backbone을 resnet101 -> efficientnet b3(향상) -> ts - efficientnet b3(감소) 
3. backbone 사용시 마지막 global avg, classifier 제거 이후, DeepLab 연결
4. avgloss 기준으로 best model를 저장 해야하는 지, accuracy로 사용해야 하는지 고민고민
5. batch size 조정 - 16
6. log만 기록 시, jupyter notebook에서 Wandb 사용 가능
7. loss 탐색 - https://github.com/JunMa11/SegLoss
8. 외부 데이터 탐색
   1. http://tacodataset.org/
   2. https://github.com/AgaMiko/waste-datasets-review

9. Data 증강
   1. 배경 제거 
   2. 쓰레기 부분만 짤라서 합성
   3. CutMix

10. Data imbalance 해결 방향

